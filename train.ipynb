{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "czhTImlt-37S",
    "outputId": "e1420cd5-9ab2-449f-d748-e0cd7759668a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f3Melxg5_B2o"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lChLMh2mWfum"
   },
   "source": [
    "# Import Encoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8TxhKmIHHJp9"
   },
   "outputs": [],
   "source": [
    "from model import Encoder, LuongAttention, LoungDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "De7lUiCQWzer"
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nh_AH5Ul_htn"
   },
   "outputs": [],
   "source": [
    "lines = io.open('/content/gdrive/My Drive/neural machine translation/hin.txt', encoding='UTF-8').read().strip().split('\\n')\n",
    "\n",
    "word_pairs = [[a for a in l.split('\\t')]  for l in lines]\n",
    "for i in range(len(word_pairs)):\n",
    "  word_pairs[i] = word_pairs[i][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "RATi8m0rDO-J",
    "outputId": "acb6ab29-f495-478f-aed6-8f143fd5424b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Apples were on sale today.', 'आज सेव सस्ते बिक रहे थे।'],\n",
       " ['As for me, I am satisfied.', 'मैं तो संतुष्ट हूँ।'],\n",
       " ['Can you come to the party?', 'तुम पार्टी में आ सकते हो क्या?'],\n",
       " ['Canada is a large country.', 'कनाडा एक बड़ा देश है ।'],\n",
       " ['Come to my house at eight.', 'मेरे घर आठ बजे आना।'],\n",
       " ['Did the police arrest Tom?', 'पुलीस ने टॉम को गिरफ़्तार किया क्या?'],\n",
       " ['Do you believe in fairies?', 'तुम परियों में विश्वास करते हो क्या?'],\n",
       " ['Do you believe in fairies?', 'तुम परियों में विश्वास करती हो क्या?'],\n",
       " ['Do you have a larger size?', 'आपके पास इससे बड़े नाप का है क्या?'],\n",
       " ['Do you want to come along?', 'तुम साथ आना चाहते हो क्या?']]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs[1000:1010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V-tFq_9kW3pI"
   },
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2pEWikt7B7go"
   },
   "outputs": [],
   "source": [
    "def unicode_to_ascii(s):\n",
    "  return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "    if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence_en(s):\n",
    "  s = unicode_to_ascii(s.lower().strip())\n",
    "  s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "  s = re.sub(r'[\" \"]+', \" \", s)\n",
    "  s = s.strip()\n",
    "  s = '<start> ' + s + ' <end>'\n",
    "  return s\n",
    "\n",
    "def preprocess_sentence_hn(s):\n",
    "  s = s.lower().strip()\n",
    "  s = re.sub(r\"([?.!|,¿])\", r\" \\1 \", s)\n",
    "  s = re.sub(r'[\" \"]+', \" \", s)\n",
    "  s = s.strip()\n",
    "  s = '<start> ' + s + ' <end>'\n",
    "  return s  \n",
    "\n",
    "def tokenize(lang):\n",
    "  tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "      filters='')\n",
    "  tokenizer.fit_on_texts(lang)\n",
    "\n",
    "  tensor = tokenizer.texts_to_sequences(lang)\n",
    "\n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "  return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "56Bwd7hjCr1R"
   },
   "outputs": [],
   "source": [
    "inp_lang = [preprocess_sentence_en(p[0]) for p in word_pairs]\n",
    "target_lang = [preprocess_sentence_hn(p[1]) for p in word_pairs]\n",
    "\n",
    "input_tensor, input_lang_tokenizer = tokenize(inp_lang)\n",
    "target_tensor, target_lang_tokenizer = tokenize(target_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GqW3iZn0DC-D",
    "outputId": "7555afc6-7910-4db8-a5e3-d4316e5afa84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2869, 27)\n",
      "(2869, 29)\n"
     ]
    }
   ],
   "source": [
    "print(input_tensor.shape)\n",
    "print(target_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFpjp8Q3FxeC"
   },
   "outputs": [],
   "source": [
    "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ps7qdvGvHs8w"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = len(input_tensor)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(input_tensor)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(input_lang_tokenizer.word_index)+1\n",
    "vocab_tar_size = len(target_lang_tokenizer.word_index)+1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor, target_tensor)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CduBk2LAW-Ud"
   },
   "source": [
    "# Initialize Encoder and Decoder models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i71bbjjJIVmz"
   },
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "attention_decoder = LoungDecoder(vocab_tar_size, embedding_dim, units, 'concat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "FweZ8UxvYn2a",
    "outputId": "7d4294e9-307b-4da2-9dbc-f6487a771a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  618496    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  5246976   \n",
      "=================================================================\n",
      "Total params: 5,865,472\n",
      "Trainable params: 5,865,472\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "G9B8mcakYqnj",
    "outputId": "43b17d81-c99d-416f-81e4-046395ea3823"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"loung_decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "luong_attention (LuongAttent multiple                  2099201   \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      multiple                  779776    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              multiple                  2098176   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  3122150   \n",
      "=================================================================\n",
      "Total params: 13,346,279\n",
      "Trainable params: 13,346,279\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attention_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eWHEbVEXI72u"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3gFpCIlzXIS0"
   },
   "source": [
    "# Training\n",
    "\n",
    "## Define single train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFbs3y9aKtZn"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "  loss = 0\n",
    "\n",
    "  with tf.GradientTape() as tape:\n",
    "\n",
    "    enc_output, enc_hidden_h, enc_hidden_c = encoder(inp, enc_hidden)\n",
    "\n",
    "    dec_hidden_h = enc_hidden_h\n",
    "    dec_hidden_c = enc_hidden_c\n",
    "\n",
    "\n",
    "    for t in range(1, targ.shape[1]):\n",
    "      # initialize decoder input to previous timestep of target\n",
    "      dec_input = tf.expand_dims(targ[:, t-1], 1)\n",
    "      \n",
    "      predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h , dec_hidden_c), enc_output)\n",
    "\n",
    "      loss += loss_function(targ[:, t], predictions)\n",
    "\n",
    "\n",
    "  batch_loss = (loss / int(targ.shape[1]))\n",
    "\n",
    "  variables = encoder.trainable_variables + attention_decoder.trainable_variables\n",
    "\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "  return batch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vTIVkDrILfdc"
   },
   "outputs": [],
   "source": [
    "def translate(sentence):\n",
    "\n",
    "  sentence = preprocess_sentence_en(sentence)\n",
    "\n",
    "  inputs = [input_lang_tokenizer.word_index[i] for i in sentence.split(' ')]\n",
    "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
    "                                                         maxlen=max_length_inp,\n",
    "                                                         padding='post')\n",
    "  inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "  result = ''\n",
    "\n",
    "  hidden = (tf.zeros([1, units]), tf.zeros([1, units]))\n",
    "\n",
    "  enc_out, dec_hidden_h, dec_hidden_c = encoder(inputs, hidden)\n",
    "\n",
    "  dec_input = tf.expand_dims([target_lang_tokenizer.word_index['<start>']], 0)\n",
    "\n",
    "  for t in range(max_length_targ):\n",
    "    predictions, dec_hidden_h, dec_hidden_c, _ = attention_decoder(dec_input, (dec_hidden_h, dec_hidden_c), enc_out)\n",
    "\n",
    "\n",
    "\n",
    "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "    # print(predicted_id)\n",
    "    result += target_lang_tokenizer.index_word[predicted_id] + ' '\n",
    "\n",
    "    if target_lang_tokenizer.index_word[predicted_id] == '<end>':\n",
    "      break\n",
    "\n",
    "    # the predicted ID is fed back into the model\n",
    "    dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "  print('Input: %s' % (sentence))\n",
    "  print('Predicted translation: {}'.format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EwhD9KVAXiT4"
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "o6n-3BzRMXfK",
    "outputId": "d592a1e7-0afe-4a52-e3d1-b7873fee8a54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.1652\n",
      "Epoch 1 Loss 1.8553\n",
      "Time taken for 1 epoch 22.59349513053894 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 1.5332\n",
      "Epoch 2 Loss 1.5627\n",
      "Time taken for 1 epoch 19.75169086456299 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 1.4556\n",
      "Epoch 3 Loss 1.4399\n",
      "Time taken for 1 epoch 20.007569551467896 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3512\n",
      "Epoch 4 Loss 1.3679\n",
      "Time taken for 1 epoch 19.680345058441162 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 1.3273\n",
      "Epoch 5 Loss 1.3101\n",
      "Time taken for 1 epoch 19.770269870758057 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 1.1678\n",
      "Epoch 6 Loss 1.2446\n",
      "Time taken for 1 epoch 19.942848205566406 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 1.1513\n",
      "Epoch 7 Loss 1.1836\n",
      "Time taken for 1 epoch 20.038758039474487 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 1.1978\n",
      "Epoch 8 Loss 1.1303\n",
      "Time taken for 1 epoch 19.878458738327026 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.0825\n",
      "Epoch 9 Loss 1.0694\n",
      "Time taken for 1 epoch 20.03354501724243 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 0.9868\n",
      "Epoch 10 Loss 1.0116\n",
      "Time taken for 1 epoch 19.868704795837402 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 0.8664\n",
      "Epoch 11 Loss 0.9522\n",
      "Time taken for 1 epoch 20.025721311569214 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 0.8166\n",
      "Epoch 12 Loss 0.8859\n",
      "Time taken for 1 epoch 20.128049612045288 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 0.7647\n",
      "Epoch 13 Loss 0.8240\n",
      "Time taken for 1 epoch 19.975080251693726 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 0.6937\n",
      "Epoch 14 Loss 0.7543\n",
      "Time taken for 1 epoch 20.06721329689026 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.6295\n",
      "Epoch 15 Loss 0.6875\n",
      "Time taken for 1 epoch 20.241215705871582 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.5612\n",
      "Epoch 16 Loss 0.6235\n",
      "Time taken for 1 epoch 20.176202535629272 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.5009\n",
      "Epoch 17 Loss 0.5606\n",
      "Time taken for 1 epoch 20.4976544380188 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.4649\n",
      "Epoch 18 Loss 0.4985\n",
      "Time taken for 1 epoch 20.17645239830017 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.4019\n",
      "Epoch 19 Loss 0.4483\n",
      "Time taken for 1 epoch 20.245136499404907 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.3683\n",
      "Epoch 20 Loss 0.4017\n",
      "Time taken for 1 epoch 19.980603456497192 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.3076\n",
      "Epoch 21 Loss 0.3626\n",
      "Time taken for 1 epoch 20.121705532073975 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.2975\n",
      "Epoch 22 Loss 0.3277\n",
      "Time taken for 1 epoch 20.1475510597229 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.2881\n",
      "Epoch 23 Loss 0.2968\n",
      "Time taken for 1 epoch 20.203770399093628 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.2376\n",
      "Epoch 24 Loss 0.2704\n",
      "Time taken for 1 epoch 20.114829301834106 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.2066\n",
      "Epoch 25 Loss 0.2479\n",
      "Time taken for 1 epoch 20.01397466659546 sec\n",
      "\n",
      "Epoch 26 Batch 0 Loss 0.1827\n",
      "Epoch 26 Loss 0.2282\n",
      "Time taken for 1 epoch 20.19628071784973 sec\n",
      "\n",
      "Epoch 27 Batch 0 Loss 0.1750\n",
      "Epoch 27 Loss 0.2094\n",
      "Time taken for 1 epoch 20.18484663963318 sec\n",
      "\n",
      "Epoch 28 Batch 0 Loss 0.1609\n",
      "Epoch 28 Loss 0.1929\n",
      "Time taken for 1 epoch 20.08030676841736 sec\n",
      "\n",
      "Epoch 29 Batch 0 Loss 0.1583\n",
      "Epoch 29 Loss 0.1785\n",
      "Time taken for 1 epoch 20.186145782470703 sec\n",
      "\n",
      "Epoch 30 Batch 0 Loss 0.1309\n",
      "Epoch 30 Loss 0.1645\n",
      "Time taken for 1 epoch 20.17199206352234 sec\n",
      "\n",
      "Epoch 31 Batch 0 Loss 0.1485\n",
      "Epoch 31 Loss 0.1502\n",
      "Time taken for 1 epoch 20.184239149093628 sec\n",
      "\n",
      "Epoch 32 Batch 0 Loss 0.1276\n",
      "Epoch 32 Loss 0.1379\n",
      "Time taken for 1 epoch 20.47787618637085 sec\n",
      "\n",
      "Epoch 33 Batch 0 Loss 0.1018\n",
      "Epoch 33 Loss 0.1268\n",
      "Time taken for 1 epoch 20.042033672332764 sec\n",
      "\n",
      "Epoch 34 Batch 0 Loss 0.0985\n",
      "Epoch 34 Loss 0.1161\n",
      "Time taken for 1 epoch 19.982226848602295 sec\n",
      "\n",
      "Epoch 35 Batch 0 Loss 0.0695\n",
      "Epoch 35 Loss 0.1063\n",
      "Time taken for 1 epoch 20.21454906463623 sec\n",
      "\n",
      "Epoch 36 Batch 0 Loss 0.0846\n",
      "Epoch 36 Loss 0.0968\n",
      "Time taken for 1 epoch 19.988209009170532 sec\n",
      "\n",
      "Epoch 37 Batch 0 Loss 0.0735\n",
      "Epoch 37 Loss 0.0865\n",
      "Time taken for 1 epoch 19.90362572669983 sec\n",
      "\n",
      "Epoch 38 Batch 0 Loss 0.0654\n",
      "Epoch 38 Loss 0.0797\n",
      "Time taken for 1 epoch 19.916067123413086 sec\n",
      "\n",
      "Epoch 39 Batch 0 Loss 0.0654\n",
      "Epoch 39 Loss 0.0739\n",
      "Time taken for 1 epoch 20.07418656349182 sec\n",
      "\n",
      "Epoch 40 Batch 0 Loss 0.0465\n",
      "Epoch 40 Loss 0.0669\n",
      "Time taken for 1 epoch 19.784372091293335 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  enc_hidden = encoder.initialize_hidden_state()\n",
    "  total_loss = 0\n",
    "\n",
    "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "    batch_loss = train_step(inp, targ, enc_hidden)\n",
    "    total_loss += batch_loss\n",
    "\n",
    "    if batch % 100 == 0:\n",
    "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                   batch,\n",
    "                                                   batch_loss.numpy()))\n",
    "\n",
    "\n",
    "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                      total_loss / steps_per_epoch))\n",
    "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjR-ojIdXnAj"
   },
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "vxlgVDItMv-R",
    "outputId": "62f0e9ae-33b6-4a1a-b270-9703aee28c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> this is book . <end>\n",
      "Predicted translation: यह किताब है। <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'this is book.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "LoeTr8YmO5Sf",
    "outputId": "87124aa3-96e2-4420-d566-ba40e8c6c49b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> are you at home ? <end>\n",
      "Predicted translation: तुम घर पे हो क्या ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'are you at home ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "4K6XDGH8PjQ4",
    "outputId": "bbbb725b-45d2-477d-e434-b93137f40f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> what is this ? <end>\n",
      "Predicted translation: यह क्या है ? <end> \n"
     ]
    }
   ],
   "source": [
    "translate(u'what is this ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EqYeWszNaweO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
